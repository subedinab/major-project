{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chhetri123/Major_Project/blob/master/cultural_heritage_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. # Image Classification using Resnet9 model\n",
        "\n",
        "Here, I am using cultural heritage dataset, a dataset with around 2.5k images of 6 cultural heritage sites around the nepal.\n",
        "\n",
        "Url of the dataset : https://www.kaggle.com/datasets/nabarajsubedi/tcultural-heritage-classification\n",
        "\n",
        "Dataset properties :\n",
        "\n",
        "        Total number of images : 2476 images\n",
        "\n",
        "        Training set size : 2000 images\n",
        "\n",
        "        Test set size : 3000 images\n",
        "\n",
        "        Pred set size : 7301 images\n",
        "\n",
        "        Number of classes : 6\n",
        "\n",
        "        Classes : 'Bhaktapur_Durbar_Square', 'Patan Dhurbar Square', 'phasupatinath', 'lumbini', 'swayambhunath', 'Boudhha'\n",
        "\n",
        "        Image size : 150x150 pixels"
      ],
      "metadata": {
        "id": "r5R-S0LkzD1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9MQ8bmCzP0z",
        "outputId": "3d55276e-4bc0-41f7-ac45-c598e16bf3f8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ooVK4eahzD1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import tarfile\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as tt\n",
        "from torch.utils.data import Dataset, random_split, DataLoader\n",
        "from torchvision.utils import make_grid\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "execution": {
          "iopub.status.busy": "2023-07-12T20:03:36.323532Z",
          "iopub.execute_input": "2023-07-12T20:03:36.324173Z",
          "iopub.status.idle": "2023-07-12T20:03:39.894627Z",
          "shell.execute_reply.started": "2023-07-12T20:03:36.324133Z",
          "shell.execute_reply": "2023-07-12T20:03:39.893470Z"
        },
        "trusted": true,
        "id": "lmMERRIQzD1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "project_name='image-classification-resnet9'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T20:03:53.494623Z",
          "iopub.execute_input": "2023-07-12T20:03:53.495231Z",
          "iopub.status.idle": "2023-07-12T20:03:53.499733Z",
          "shell.execute_reply.started": "2023-07-12T20:03:53.495197Z",
          "shell.execute_reply": "2023-07-12T20:03:53.498950Z"
        },
        "trusted": true,
        "id": "enQF6UuIzD1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploring the dataset"
      ],
      "metadata": {
        "id": "pskkg_gIzD1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '../input/tcultural-heritage-classification/classification'\n",
        "print(os.listdir(data_dir))\n",
        "classes = os.listdir(data_dir + \"/seg_train/seg_train\")\n",
        "print(classes)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T20:05:00.014716Z",
          "iopub.execute_input": "2023-07-12T20:05:00.015200Z",
          "iopub.status.idle": "2023-07-12T20:05:00.028895Z",
          "shell.execute_reply.started": "2023-07-12T20:05:00.015160Z",
          "shell.execute_reply": "2023-07-12T20:05:00.027550Z"
        },
        "trusted": true,
        "id": "47237LE4zD1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing Datasets and Dataloaders"
      ],
      "metadata": {
        "id": "EQu9ILndzD1h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing\n",
        "\n",
        "Before we create our dataset, we have do **Data Augmentation** which is a technique that can be used to artificially expand the size of a training dataset by creating modified versions of images in the dataset. In order to improve the performance and ability of the model to generalize.\n",
        "\n",
        "We can do this by resizing, shifting, flipping, croping, zoom-in or zoom-out a images and many more...\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "r7kiwtIgzD1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_tfms = tt.Compose([tt.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
        "                         tt.Resize((150,150)),\n",
        "                         tt.RandomCrop(150, padding=4, padding_mode='reflect'),\n",
        "                         tt.RandomHorizontalFlip(),\n",
        "                         tt.RandomRotation(10),\n",
        "                         tt.ToTensor()])\n",
        "                        # tt.Normalize(*stats,inplace=True)])\n",
        "valid_tfms = tt.Compose([tt.Resize((150,150)),tt.ToTensor()])#, tt.Normalize(*stats)])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T20:05:19.873777Z",
          "iopub.execute_input": "2023-07-12T20:05:19.874176Z",
          "iopub.status.idle": "2023-07-12T20:05:19.881923Z",
          "shell.execute_reply.started": "2023-07-12T20:05:19.874144Z",
          "shell.execute_reply": "2023-07-12T20:05:19.880904Z"
        },
        "trusted": true,
        "id": "yCugetZlzD1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset is split into 3 parts :\n",
        "\n",
        "* Training set : This is used to train the model i.e. compute the loss and adjust the weights of the model using gradient descent.\n",
        "* Validation set : This is used to evaluate the model while training, adjust hyperparameters (learning rate etc.) and pick the best version of the model.\n",
        "* Test set : This is used to compare different models, or different types of modeling approaches, and report the final accuracy of the model."
      ],
      "metadata": {
        "id": "iF8Ol7UBzD1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = ImageFolder(data_dir+'/seg_train/seg_train', train_tfms)\n",
        "valid_ds = ImageFolder(data_dir+'/seg_test/seg_test', valid_tfms)\n",
        "test_ds = ImageFolder(data_dir+'/seg_pred', transform=valid_tfms)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T20:05:29.348098Z",
          "iopub.execute_input": "2023-07-12T20:05:29.349237Z",
          "iopub.status.idle": "2023-07-12T20:05:29.889383Z",
          "shell.execute_reply.started": "2023-07-12T20:05:29.349196Z",
          "shell.execute_reply": "2023-07-12T20:05:29.888324Z"
        },
        "trusted": true,
        "id": "HbvQAZUNzD1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_ds), len(valid_ds), len(test_ds)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T20:05:37.784550Z",
          "iopub.execute_input": "2023-07-12T20:05:37.785091Z",
          "iopub.status.idle": "2023-07-12T20:05:37.793995Z",
          "shell.execute_reply.started": "2023-07-12T20:05:37.785051Z",
          "shell.execute_reply": "2023-07-12T20:05:37.792942Z"
        },
        "trusted": true,
        "id": "Yu7bZnEEzD1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each element from the training dataset is a tuple, containing a image tensor and a label. Since the data consists of 150 x 150 px color images with 3 channels (RGB). So, each image tensor has the shape (3, 150, 150) :"
      ],
      "metadata": {
        "id": "HR0XzwPvzD1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = train_ds[0]\n",
        "img_shape = img.shape\n",
        "img_shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T20:05:45.092983Z",
          "iopub.execute_input": "2023-07-12T20:05:45.093335Z",
          "iopub.status.idle": "2023-07-12T20:05:45.214458Z",
          "shell.execute_reply.started": "2023-07-12T20:05:45.093309Z",
          "shell.execute_reply": "2023-07-12T20:05:45.213731Z"
        },
        "trusted": true,
        "id": "kFS0A8JezD1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The list of classes is stored in the .classes property of the dataset. The numeric label for each element corresponds to index of the element's label in the list of classes."
      ],
      "metadata": {
        "id": "nMx9pBObzD1k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds.classes"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T20:05:50.821088Z",
          "iopub.execute_input": "2023-07-12T20:05:50.821693Z",
          "iopub.status.idle": "2023-07-12T20:05:50.828617Z",
          "shell.execute_reply.started": "2023-07-12T20:05:50.821660Z",
          "shell.execute_reply": "2023-07-12T20:05:50.827568Z"
        },
        "trusted": true,
        "id": "7DKb097FzD1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset consists of 3-channel color images (RGB). We can view the image using matplotlib, but we need to change the tensor dimensions to (150,150,3) as matplotlib expects channels to be the last dimension of the image tensors (whereas in PyTorch they are the first dimension), so we'll the .permute tensor method to shift channels to the last dimension. Let's create a helper function to display an image and its label."
      ],
      "metadata": {
        "id": "RrWZQjjQzD1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def show_example(img, label):\n",
        "    print('Label: ', train_ds.classes[label], \"(\"+str(label)+\")\")\n",
        "    plt.imshow(img.permute(1, 2, 0))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T20:05:59.797496Z",
          "iopub.execute_input": "2023-07-12T20:05:59.797894Z",
          "iopub.status.idle": "2023-07-12T20:05:59.803074Z",
          "shell.execute_reply.started": "2023-07-12T20:05:59.797851Z",
          "shell.execute_reply": "2023-07-12T20:05:59.802256Z"
        },
        "trusted": true,
        "id": "e-vXTptBzD1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_example(*train_ds[1])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T20:06:09.892539Z",
          "iopub.execute_input": "2023-07-12T20:06:09.893123Z",
          "iopub.status.idle": "2023-07-12T20:06:10.322049Z",
          "shell.execute_reply.started": "2023-07-12T20:06:09.893090Z",
          "shell.execute_reply": "2023-07-12T20:06:10.321101Z"
        },
        "trusted": true,
        "id": "Ciep94inzD1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_example(*train_ds[800])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T20:06:39.168802Z",
          "iopub.execute_input": "2023-07-12T20:06:39.169368Z",
          "iopub.status.idle": "2023-07-12T20:06:39.573507Z",
          "shell.execute_reply.started": "2023-07-12T20:06:39.169329Z",
          "shell.execute_reply": "2023-07-12T20:06:39.572535Z"
        },
        "trusted": true,
        "id": "SH5FjboRzD1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we'll create a DataLoader, which can split the data into batches of a predefined size while training. It also provides other utilities like shuffling and random sampling of the data."
      ],
      "metadata": {
        "id": "htGvq6qLzD1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T20:06:50.635384Z",
          "iopub.execute_input": "2023-07-12T20:06:50.636548Z",
          "iopub.status.idle": "2023-07-12T20:06:50.640407Z",
          "shell.execute_reply.started": "2023-07-12T20:06:50.636510Z",
          "shell.execute_reply": "2023-07-12T20:06:50.639409Z"
        },
        "trusted": true,
        "id": "Ti3FDySgzD1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch data loaders\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=3, pin_memory=True)\n",
        "valid_dl = DataLoader(valid_ds, batch_size*2, num_workers=3, pin_memory=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T20:06:56.085492Z",
          "iopub.execute_input": "2023-07-12T20:06:56.085920Z",
          "iopub.status.idle": "2023-07-12T20:06:56.091554Z",
          "shell.execute_reply.started": "2023-07-12T20:06:56.085868Z",
          "shell.execute_reply": "2023-07-12T20:06:56.090522Z"
        },
        "trusted": true,
        "id": "POJYSoOFzD1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at the batches of images from the dataset using the make_grid method from torchvision :"
      ],
      "metadata": {
        "id": "HzNDtF3rzD1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_batch(dl):\n",
        "    for images, labels in dl:\n",
        "        fig, ax = plt.subplots(figsize=(12, 12))\n",
        "        ax.set_xticks([]); ax.set_yticks([])\n",
        "        ax.imshow(make_grid(images[:32], nrow=8).permute(1, 2, 0))\n",
        "        break"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T20:07:01.122794Z",
          "iopub.execute_input": "2023-07-12T20:07:01.123194Z",
          "iopub.status.idle": "2023-07-12T20:07:01.129157Z",
          "shell.execute_reply.started": "2023-07-12T20:07:01.123162Z",
          "shell.execute_reply": "2023-07-12T20:07:01.127951Z"
        },
        "trusted": true,
        "id": "_F8-GtHpzD1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_batch(train_dl)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T20:07:06.784668Z",
          "iopub.execute_input": "2023-07-12T20:07:06.785351Z",
          "iopub.status.idle": "2023-07-12T20:07:14.507443Z",
          "shell.execute_reply.started": "2023-07-12T20:07:06.785316Z",
          "shell.execute_reply": "2023-07-12T20:07:14.506049Z"
        },
        "trusted": true,
        "id": "5hCcnh_mzD1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using a GPU\n",
        "It is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized for general purpose and GPUs are optimized for training artificial intelligence and deep learning models as they can process multiple computations simultaneously. They have a large number of cores, which allows for better computation of multiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of data — this makes a GPU’s memory bandwidth most suitable.\n",
        "\n",
        "To seamlessly use a GPU, if one is available, we define a couple of helper functions (get_default_device & to_device) and a helper class DeviceDataLoader to move our model & data to the GPU as required."
      ],
      "metadata": {
        "id": "-zlnbgk2zD1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "\n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "\n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl:\n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T20:07:23.420851Z",
          "iopub.execute_input": "2023-07-12T20:07:23.421529Z",
          "iopub.status.idle": "2023-07-12T20:07:23.432676Z",
          "shell.execute_reply.started": "2023-07-12T20:07:23.421472Z",
          "shell.execute_reply": "2023-07-12T20:07:23.431582Z"
        },
        "trusted": true,
        "id": "CGSS-xqczD1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = get_default_device()\n",
        "device"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T20:07:30.383366Z",
          "iopub.execute_input": "2023-07-12T20:07:30.383762Z",
          "iopub.status.idle": "2023-07-12T20:07:30.390608Z",
          "shell.execute_reply.started": "2023-07-12T20:07:30.383715Z",
          "shell.execute_reply": "2023-07-12T20:07:30.389640Z"
        },
        "trusted": true,
        "id": "I1h0xNOgzD1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now wrap up our training and validation data loaders using DeviceDataLoader for automatically transferring batches of data to the GPU (if available)."
      ],
      "metadata": {
        "id": "fBwHHFm9zD1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl = DeviceDataLoader(train_dl, device)\n",
        "valid_dl = DeviceDataLoader(valid_dl, device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T20:07:39.196789Z",
          "iopub.execute_input": "2023-07-12T20:07:39.197167Z",
          "iopub.status.idle": "2023-07-12T20:07:39.201510Z",
          "shell.execute_reply.started": "2023-07-12T20:07:39.197138Z",
          "shell.execute_reply": "2023-07-12T20:07:39.200718Z"
        },
        "trusted": true,
        "id": "cne5AUEbzD1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Our Model\n"
      ],
      "metadata": {
        "id": "wmZ1AqgszD1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this model, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with residual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to avoid overfitting."
      ],
      "metadata": {
        "id": "aKFyvj0kzD1r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleResidualBlock(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.relu1(out)\n",
        "        out = self.conv2(out)\n",
        "        return self.relu2(out) + x # ReLU can be applied before or after adding the input"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T20:07:47.130394Z",
          "iopub.execute_input": "2023-07-12T20:07:47.131373Z",
          "iopub.status.idle": "2023-07-12T20:07:47.137577Z",
          "shell.execute_reply.started": "2023-07-12T20:07:47.131322Z",
          "shell.execute_reply": "2023-07-12T20:07:47.136430Z"
        },
        "trusted": true,
        "id": "_NV1rO_TzD1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simple_resnet = to_device(SimpleResidualBlock(), device)\n",
        "\n",
        "for images, labels in train_dl:\n",
        "    out = simple_resnet(images)\n",
        "    print(out.shape)\n",
        "    break\n",
        "\n",
        "del simple_resnet, images, labels\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T20:07:54.369466Z",
          "iopub.execute_input": "2023-07-12T20:07:54.369863Z",
          "iopub.status.idle": "2023-07-12T20:08:02.165845Z",
          "shell.execute_reply.started": "2023-07-12T20:07:54.369819Z",
          "shell.execute_reply": "2023-07-12T20:08:02.164843Z"
        },
        "trusted": true,
        "id": "WS9xf32izD1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
        "\n",
        "class ImageClassificationBase(nn.Module):\n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch\n",
        "        out = self(images)                  # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch\n",
        "        out = self(images)                    # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
        "        acc = accuracy(out, labels)           # Calculate accuracy\n",
        "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "\n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
        "            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_acc']))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T20:08:05.023112Z",
          "iopub.execute_input": "2023-07-12T20:08:05.023925Z",
          "iopub.status.idle": "2023-07-12T20:08:05.035289Z",
          "shell.execute_reply.started": "2023-07-12T20:08:05.023868Z",
          "shell.execute_reply": "2023-07-12T20:08:05.034267Z"
        },
        "trusted": true,
        "id": "ouV0MofczD1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(in_channels, out_channels, pool=False, pool_no=2):\n",
        "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "              nn.BatchNorm2d(out_channels),\n",
        "              nn.ReLU(inplace=True)]\n",
        "    if pool: layers.append(nn.MaxPool2d(pool_no))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "class ResNet9(ImageClassificationBase):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = conv_block(in_channels, 64)\n",
        "        self.conv2 = conv_block(64, 128, pool=True, pool_no=3)\n",
        "        self.res1 = nn.Sequential(conv_block(128, 128), conv_block(128, 128))\n",
        "\n",
        "        self.conv3 = conv_block(128, 256, pool=True)\n",
        "        self.conv4 = conv_block(256, 512, pool=True, pool_no=5)\n",
        "        self.res2 = nn.Sequential(conv_block(512, 512), conv_block(512, 512))\n",
        "\n",
        "        self.classifier = nn.Sequential(nn.MaxPool2d(5),\n",
        "                                        nn.Flatten(),\n",
        "                                        nn.Linear(512, num_classes))\n",
        "\n",
        "    def forward(self, xb):\n",
        "        out = self.conv1(xb)\n",
        "        out = self.conv2(out)\n",
        "        out = self.res1(out) + out\n",
        "        out = self.conv3(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.res2(out) + out\n",
        "        out = self.classifier(out)\n",
        "        return out"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T20:08:14.867383Z",
          "iopub.execute_input": "2023-07-12T20:08:14.868093Z",
          "iopub.status.idle": "2023-07-12T20:08:14.877900Z",
          "shell.execute_reply.started": "2023-07-12T20:08:14.868060Z",
          "shell.execute_reply": "2023-07-12T20:08:14.876933Z"
        },
        "trusted": true,
        "id": "S3CwHVCqzD1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = to_device(ResNet9(3, 6), device)\n",
        "model"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T20:08:22.395643Z",
          "iopub.execute_input": "2023-07-12T20:08:22.396004Z",
          "iopub.status.idle": "2023-07-12T20:08:22.466601Z",
          "shell.execute_reply.started": "2023-07-12T20:08:22.395976Z",
          "shell.execute_reply": "2023-07-12T20:08:22.465932Z"
        },
        "trusted": true,
        "id": "jkNEXw8uzD1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Our Model"
      ],
      "metadata": {
        "id": "cAjB0OnRzD1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "def fit_one_cycle(epochs, max_lr, model, train_loader, val_loader,\n",
        "                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n",
        "    torch.cuda.empty_cache()\n",
        "    history = []\n",
        "\n",
        "    # Set up cutom optimizer with weight decay\n",
        "    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
        "    # Set up one-cycle learning rate scheduler\n",
        "    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs,\n",
        "                                                steps_per_epoch=len(train_loader))\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase\n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        lrs = []\n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "\n",
        "            # Gradient clipping\n",
        "            if grad_clip:\n",
        "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
        "\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Record & update learning rate\n",
        "            lrs.append(get_lr(optimizer))\n",
        "            sched.step()\n",
        "\n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        result['lrs'] = lrs\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "    return history"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T20:08:29.891729Z",
          "iopub.execute_input": "2023-07-12T20:08:29.892132Z",
          "iopub.status.idle": "2023-07-12T20:08:29.902970Z",
          "shell.execute_reply.started": "2023-07-12T20:08:29.892091Z",
          "shell.execute_reply": "2023-07-12T20:08:29.901913Z"
        },
        "trusted": true,
        "id": "-MKx-vcWzD17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = [evaluate(model, valid_dl)]\n",
        "history"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T20:08:37.742947Z",
          "iopub.execute_input": "2023-07-12T20:08:37.743869Z",
          "iopub.status.idle": "2023-07-12T20:12:22.103483Z",
          "shell.execute_reply.started": "2023-07-12T20:08:37.743836Z",
          "shell.execute_reply": "2023-07-12T20:12:22.102564Z"
        },
        "trusted": true,
        "id": "yhjKmjizzD17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 8\n",
        "max_lr = 0.001\n",
        "grad_clip = 0.1\n",
        "weight_decay = 1e-4\n",
        "opt_func = torch.optim.AdamW"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T20:12:31.334498Z",
          "iopub.execute_input": "2023-07-12T20:12:31.335436Z",
          "iopub.status.idle": "2023-07-12T20:12:31.340614Z",
          "shell.execute_reply.started": "2023-07-12T20:12:31.335395Z",
          "shell.execute_reply": "2023-07-12T20:12:31.339507Z"
        },
        "trusted": true,
        "id": "hM3206QvzD18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "history += fit_one_cycle(epochs, max_lr, model, train_dl, valid_dl,\n",
        "                             grad_clip=grad_clip,\n",
        "                             weight_decay=weight_decay,\n",
        "                             opt_func=opt_func)"
      ],
      "metadata": {
        "trusted": true,
        "id": "C1vz1JSazD18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_time='9:58'"
      ],
      "metadata": {
        "trusted": true,
        "id": "Sid1a3NlzD18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's plot the valdation set accuracies to study how the model improves over time."
      ],
      "metadata": {
        "id": "k5ULGjhUzD19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_accuracies(history):\n",
        "    accuracies = [x['val_acc'] for x in history]\n",
        "    plt.plot(accuracies, '-x')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.title('Accuracy vs. No. of epochs');"
      ],
      "metadata": {
        "trusted": true,
        "id": "NGsgqWBhzD19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_accuracies(history)"
      ],
      "metadata": {
        "trusted": true,
        "id": "SIPYr7QkzD1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's plot the training and validation losses to study the trend."
      ],
      "metadata": {
        "id": "095J_R7tzD1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_losses(history):\n",
        "    train_losses = [x.get('train_loss') for x in history]\n",
        "    val_losses = [x['val_loss'] for x in history]\n",
        "    plt.plot(train_losses, '-bx')\n",
        "    plt.plot(val_losses, '-rx')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.legend(['Training', 'Validation'])\n",
        "    plt.title('Loss vs. No. of epochs');"
      ],
      "metadata": {
        "trusted": true,
        "id": "7n-wvAOazD1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_losses(history)"
      ],
      "metadata": {
        "trusted": true,
        "id": "Ed9cyaIkzD1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's clear from the trend that our model isn't overfitting to the training data just yet. Finally, let's visualize how the learning rate changed over time, batch-by-batch over all the epochs."
      ],
      "metadata": {
        "id": "0WgAZkMHzD2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_lrs(history):\n",
        "    lrs = np.concatenate([x.get('lrs', []) for x in history])\n",
        "    plt.plot(lrs)\n",
        "    plt.xlabel('Batch no.')\n",
        "    plt.ylabel('Learning rate')\n",
        "    plt.title('Learning Rate vs. Batch no.');"
      ],
      "metadata": {
        "trusted": true,
        "id": "4--dboDSzD2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_lrs(history)"
      ],
      "metadata": {
        "trusted": true,
        "id": "zlo4YfT3zD2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predictions..."
      ],
      "metadata": {
        "id": "dYkCC8gbzD2C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's predict some images. In this dataset test_ds dataset doesn't have labels but images are pretty much clear that we can guess it by seeing that our model predict it well or not."
      ],
      "metadata": {
        "id": "iHqBTxRDzD2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_image(img, model):\n",
        "    # Convert to a batch of 1\n",
        "    xb = to_device(img.unsqueeze(0), device)\n",
        "    # Get predictions from model\n",
        "    yb = model(xb)\n",
        "    # Pick index with highest probability\n",
        "    _, preds  = torch.max(yb, dim=1)\n",
        "    # Retrieve the class label\n",
        "    return train_ds.classes[preds[0].item()]"
      ],
      "metadata": {
        "trusted": true,
        "id": "iSjiPlE6zD2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, _= test_ds[90]\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "print('Predicted:', predict_image(img, model))"
      ],
      "metadata": {
        "trusted": true,
        "id": "i2RhBp6dzD2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, _= test_ds[219]\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "print('Predicted:', predict_image(img, model))"
      ],
      "metadata": {
        "trusted": true,
        "id": "F9vm3RKnzD2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, _= test_ds[67]\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "print('Predicted:', predict_image(img, model))"
      ],
      "metadata": {
        "trusted": true,
        "id": "B102pOyyzD2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, _= test_ds[79]\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "print('Predicted:', predict_image(img, model))"
      ],
      "metadata": {
        "trusted": true,
        "id": "-WNucDtQzD2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, _= test_ds[489]\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "print('Predicted:', predict_image(img, model))"
      ],
      "metadata": {
        "trusted": true,
        "id": "5D1735slzD2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pretty well predictions!!!\n"
      ],
      "metadata": {
        "id": "0QSWHqaczD2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img, _= test_ds[6432]\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "print('Predicted:', predict_image(img, model))"
      ],
      "metadata": {
        "trusted": true,
        "id": "85lyASjXzD2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**But, here are some images that even we could confused too.**"
      ],
      "metadata": {
        "id": "Q83oHh0ZzD2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img, _= test_ds[745]\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "print('Predicted:', predict_image(img, model))"
      ],
      "metadata": {
        "trusted": true,
        "id": "ORqXGrFRzD2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, _= test_ds[725]\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "print('Predicted:', predict_image(img, model))"
      ],
      "metadata": {
        "trusted": true,
        "id": "oY2Ja4dpzD2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There two classes 'building' or 'street' are present in these image. Model can guess any of them, and even we too. I cannot say anything about these which one is right or wrong prediction, and labels for test_ds data set is also not given. This can be resolved by multi-label image classification problem, where each image can belong to several classes or take that data set having each data belong to any one of the given class and test data set also have the labels…."
      ],
      "metadata": {
        "id": "w4HH4_EJzD2M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Though our model able to predict images with the about 91% accuracy..."
      ],
      "metadata": {
        "id": "FA0mivM6zD2N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save and commit the model and notebook"
      ],
      "metadata": {
        "id": "AAyOPlmgzD2N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we've trained our model for a long time and achieved a resonable accuracy, it would be a good idea to save the weights and bias matrices to disk, so that we can reuse the model later and avoid retraining from scratch. Here's how you can save the model."
      ],
      "metadata": {
        "id": "m6AGgqvKzD2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'image-classification-resnet.pth')"
      ],
      "metadata": {
        "trusted": true,
        "id": "pDgH5BrIzD2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jovian --upgrade --quiet"
      ],
      "metadata": {
        "trusted": true,
        "id": "n2Kj8IoLzD2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import jovian"
      ],
      "metadata": {
        "trusted": true,
        "id": "n4QcGYdRzD2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Record the hyperparameters of every experiment we do, to replicate it later and compare it against other experiments. We can record them using jovian.log_hyperparams."
      ],
      "metadata": {
        "id": "ddLO66WgzD2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "jovian.reset()\n",
        "jovian.log_hyperparams(arch='resnet9',\n",
        "                       epochs=epochs,\n",
        "                       lr=max_lr,\n",
        "                       scheduler='one-cycle',\n",
        "                       weight_decay=weight_decay,\n",
        "                       grad_clip=grad_clip,\n",
        "                       opt=opt_func.__name__)"
      ],
      "metadata": {
        "trusted": true,
        "id": "nLO4KnhqzD2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just as we have recorded the hyperparameters, we can also record the final metrics achieved by the model using jovian.log_metrics for reference, analysis and comparison."
      ],
      "metadata": {
        "id": "c2RM8vzQzD2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "jovian.log_metrics(val_loss=history[-1]['val_loss'],\n",
        "                   val_acc=history[-1]['val_acc'],\n",
        "                   train_loss=history[-1]['train_loss'],\n",
        "                   time=train_time)"
      ],
      "metadata": {
        "trusted": true,
        "id": "nRnqu_AJzD2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, save and commit our work using the jovian library. Along with the notebook, we can also attach the weights of our trained model, so that we can use it later."
      ],
      "metadata": {
        "id": "dKrdglj-zD2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "jovian.commit(project=project_name, environment=None, outputs=['image-classification-resnet.pth'])"
      ],
      "metadata": {
        "trusted": true,
        "id": "BrsdsSdxzD2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "hpHBn7sozD2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "7KJFUd20zD2T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}